<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Swapneel Wagholikar</title>
  
  <meta name="author" content="Swapneel Wagholikar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/wpi_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:43%;vertical-align:middle">
              <p style="text-align:center">
                <name>Swapneel Wagholikar</name>
              </p>
              <p> I am currently a Robotics Master's student at <a href="https://www.wpi.edu/academics/departments/robotics-engineering">Worcester Polytechnic Institute</a> graduating in May 2024. I have had the opportunity to be a part of multiple projects affiliated to <a href="https://zhang-vislab.github.io/">VISLab</a> robotics lab at WPI. I work at the intersection of Perception, Deep learning, and embedded systems.<br>
                <br>
<!--                 My passion for robotics stems from my love for building and bringing things to life, and I am excited to continue exploring the possibilities in this field.  -->
<!--                 <br> -->
                  At WPI, I have worked on a Directed research, where I am advised by <a href="https://zhang-vislab.github.io/">Prof. Ziming Zhang</a> for implementation of PointAttN: Tranformer Network for Point Cloud Completion which aims to pay attention to the relationships between points without dividing shapes into smaller regions. During the summer of 2023, I completed an internship at <a href="https://www.linkedin.com/company/void-robotics/">Void Robotics</a>, where my work revolved around Sensor Fusion of Odometry data from ZED2 depth camera and RTK-GPS Sensor. 
                <br><br>
                <!-- <br><br> -->
                  Currently, I am working in <a href="http://www.dekaresearch.com/">DEKA Research and Development</a> as a Robotics Software Intern (Perception) where I am working on Sentry bot to create high quality depth maps through classical computer vision and Deep Learning. Along with that, I am fulfilling the role of Deep Learning Researcher at <a href="https://findability.ai/">Findability Sciences</a> where I am developing an LLM-based conversational interface for business users.
                <br><br>
                <span style="color: red; font-weight: bold;">
                I am actively looking for Full-time opportunities in Robotics, Deep Learning, Embedded Systems and Software industry starting May/June 2024.</span> I believe that diversity can bring up new perspectives and will spark brilliant ideas. I look forward to learning with experts in academia and industry. Please feel free to reach out to me at <a href="swagholikar@wpi.edu">swagholikar@wpi.edu</a> <br>
                <br><br>
                Connect with me on <a href="https://www.linkedin.com/in/swapneel-wagholikar-96017515a/">LinkedIn</a>.
                
              </p>
              <p style="text-align:center">
                Email  &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp 
                Resume &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp 
                GitHub
              </p>
              <p style="text-align:center">
                
                <a href="mailto:swagholikar@wpi.edu"><img width="50" height="50" alt="mail icon" src="images/mail_icon.png" class="hoverZoomLink"></a> &nbsp &nbsp &nbsp &nbsp &nbsp
                <a href="data/Swapneel_Wagholikar_Resume.pdf"><img width="50" height="50" alt="resume icon" src="images/res_icon.png" class="hoverZoomLink"></a> &nbsp &nbsp &nbsp &nbsp &nbsp
                <a href="https://github.com/swagholikar29"><img width="50" height="50" alt="git icon" src="images/git_icon.png" class="hoverZoomLink"></a> 
              </p>
<!--               <p style="text-align:center">
                <a href="mailto:rbhikulej@seas.upenn.edu">Email</a> &nbsp/&nbsp
                <a href="data/Swapneel_Wagholikar_Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/rohiitb">github</a> &nbsp
              </p> -->
            </td>
            <td style="padding:2.5%;width:100%;max-width:120%">
              <a href="images/profile_pic1.jpg"><img style="width:100%;max-width:150%" alt="profile photo" src="images/profile_pic1.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <!-- Skills Section -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:0px;width:100%;vertical-align:middle">
                <heading>Skills</heading>
              </td>
            </tr>
          </tbody>
        </table>
        <br>

        <!-- List of Skills -->
        <ul style="margin-top:0px;">
          <li><b>Programming:</b> Python, C++, C, Matlab, Arduino, HTML, BASH</li>
          <li><b>Frameworks:</b> PyTorch, TensorFlow, ONNX, CUDA, Open3D, NumPy, ROS, ROS2, Gazebo, Linux, Git, Docker, Flask</li>
          <li><b>DL Architectures:</b> VGG16, NeRF, CompletionFormer, RangeNet, Segformer, Mask R-CNN, Transformers, LSTM</li>
        </ul>
        
<!--         Education starts here-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <heading>Education</heading>
              </td>
            </tr>
          </tbody>
        </table>
        <br>
        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Worcester Polytechnic Institute</papertitle> (Worcester, MA)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                August 2022 - May 2024 (Expected)
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Master of Science in Robotics Engineering</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 4.0/4.0
              </td>              
            </tr>
          </tbody>
        </table>
        <b><u>Topics of Interest</u> : </b>Computer Vision, Machine Perception, Camera calibration, Multi-sensor Fusion, Neural architectures, Deep Learning, Motion Planning, Navigation, Robotics.
        <ul style="margin-top:0px;">
          <li>Teaching Assistant for MA 1022 : Calculus II (Fall 2022)</li>
          <li>Teaching Assistant for MA 1024 : Calculus IV (Spring 2023)</li>
       <!--   <li>Teaching Assistant for MEAM 211 : Engineering Physics (Dynamics) (Spring 2022, Spring 2023)</li>   -->
        </ul>

                <!-- Deep Learning Researcher Position -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                  <tbody>
                    <tr>
                      <td style="paddi0px;width:70%;vrtical-align:middle">
                        <b><u>Research Experience</u> : </b> Findability Sciences
                      </td>
                      <td style="paddi0px;width:30%;vrtical-align:middle">
                        January 2024 - Ongoing
                      </td>              
                    </tr>
                  </tbody>
                </table>
        
                
<!--         <b><u>Research Experience</u> : </b> mLAB (GRASP) -->
        <ul style="margin-top:0px;">
          <li>Developing an LLM-based conversational interface for business users to request database records and industry reports. </li>
          <li>Fine-tuning foundational large language models like Llama using market forecasts and real estate-related analyst reports.</li>
          <li>Working on Retrieval Augmented Generation (RAG), SQL Generation and Large Language Model (LLM) optimization.</li>
          <!-- <li>Implemented cross layer information integration in the PointAttN Network and enhanced the baseline results by 20%.</li> -->
        </ul>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <b><u>Research Experience</u> : </b> VISLab
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                May 2023 - August 2023
              </td>              
            </tr>
          </tbody>
        </table>

        
<!--         <b><u>Research Experience</u> : </b> mLAB (GRASP) -->
        <ul style="margin-top:0px;">
          <li>Implementated PointAttN: a Tranformer Network for Point Cloud Completion. </li>
          <li>Experimented with the Geometric Details Perceptron (GDP) and Self Feature Augment (SFA) blocks in encoder.</li>
          <li>Network paid attention to the relationsships between points without dividing shapes into smaller regions.</li>
          <li>Implemented cross layer information integration in the PointAttN Network and enhanced the baseline results by 20%.</li>
        </ul>
        

<!--         Internship Experience starts here-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <heading>Internship Experience</heading>
              </td>
            </tr>
          </tbody>
        </table>
        <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>DEKA Research and Development</papertitle> (Manchester, NH)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                September 2023 - Ongoing
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Robotics Intern (Perception)</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
              <!--  GPA : 4.0/4.0 -->
              </td>              
            </tr>
          </tbody>
        </table>
        <!-- <b><u>Topics of Interest</u> : </b>Computer Vision, Machine Perception, Camera calibration, Multi-sensor Fusion, Neural architectures, Deep Learning, Motion Planning. -->
        <ul style="margin-top:0px;">
          <li>Working on Sentry bot to create high-quality depth maps through sensor fusion, lidar-camera calibration and classical computer vision techniques.</li>
          <li>Developing software for real-time data integration from Velodyne’s LiDAR and a pair of Long Range RGB cameras.</li>
          <li>Enhancing depth estimation CNN architecture aiming to predict the probability of terrain traversability accuarately.</li>
        <!--   <li>Teaching Assistant for MEAM 211 : Engineering Physics (Dynamics) (Spring 2022, Spring 2023)</li>   -->
        </ul>

        <br>


        <!-- Void Internship -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Void Robotics</papertitle> (Marathon, FL)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                May 2023 - August 2023
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Robotics Software Intern (Perception, Navigation)</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
              <!--  GPA : 4.0/4.0 -->
              </td>              
            </tr>
          </tbody>
        </table>
        <!-- <b><u>Topics of Interest</u> : </b>Computer Vision, Machine Perception, Camera calibration, Multi-sensor Fusion, Neural architectures, Deep Learning, Motion Planning. -->
        <ul style="margin-top:0px;">
          <li>Worked on ZED2/GNSS Odometry Fusion to get an accurate position of the voidwalking bot. The final odometry integrated RTK GPS + Visual Odometry + IMU. Enabled the bot to walk GPS and ZED2 within an accuracy of 1cm.</li>
          <li>Autumated test cases in ROS2 for line rendering in RVIZ via calling the sevice through rqt.</li>
          <li>Constructed a Docker-integrated ROS package for SLAM on the environment resulting in a 15% productivity boost.</li>
        <!--   <li>Teaching Assistant for MEAM 211 : Engineering Physics (Dynamics) (Spring 2022, Spring 2023)</li>   -->
        </ul>

        <br>

        <!-- Aespaes Internship -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Aespaes Labs Pvt. Ltd.</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                May 2020 - Nov 2020
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>AI Intern (Computer Vision)</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
              <!--  GPA : 4.0/4.0 -->
              </td>              
            </tr>
          </tbody>
        </table>
        <!-- <b><u>Topics of Interest</u> : </b>Computer Vision, Machine Perception, Camera calibration, Multi-sensor Fusion, Neural architectures, Deep Learning, Motion Planning. -->
        <ul style="margin-top:0px;">
          <li>Developed a deep learning pipeline for detection of O-ring in Camshaft and classification of Camshaft based on presence/absense of O-ring. Project deployed on the production line of Bajaj Auto Pvt. Ltd. Pune for inspection purposes.</li>
          <li>Augmented Reality using OpenCV to augment the blind spot at welding station for same manufacturing plant.</li>
          <li>Prototyped and proposed VR Lab to AIM Laboratory of WPI for experimentation in Biomedical Robotics Research.</li>
        <!--   <li>Teaching Assistant for MEAM 211 : Engineering Physics (Dynamics) (Spring 2022, Spring 2023)</li>   -->
        </ul>

        <br><br>
        
             
        <!-- Projects start here !-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <heading>Projects</heading>
              </td>
            </tr>
          </tbody>
        </table>
        
        
        <table style="width:130%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         
         <!-- Mobile NeLF -->

         <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/lego.gif' width="220" height="220">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Mobile NeLF</papertitle>
            <br>
            <em>Fall</em> 2023
              <br>
<!--               Code:<a href="https://github.com/rohiitb/semantic_mapping_icp"> Github</a> -->
            
            <!-- <br> -->
            Report:<a href="data/Mobile_NeRF__Real_Time_On_device_Neural_Radiance_Field_.pdf"> Link</a>

            <br>
            Code:<a href="https://github.com/swagholikar29/MobileNeLF"> GitHub</a>
            <p>Optimizing a NeLF (Neural Light Field) based novel view synthesis, with techniques such as model pruning and quantization, and
              deployed it on iPhone, demonstrating proficiency in on-device deep learning for real-time 3D novel view synthesis. 
              
              <br> 
              Guide: Prof. Bashima Islam
            </p>
          </td>
        </tr>
        
        <!-- Point Cloud Semantic Mapping -->

        <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  
          <td style="padding:20px;width:30%;vertical-align:middle">
           <div class="one">
               <img src='images/seg_combined_gif.gif' width="180" height="200">
           </div>

            <script type="text/javascript">
              function nerf_start() {
                document.getElementById('nerf_image').style.opacity = "1";
              }

              function nerf_stop() {
                document.getElementById('nerf_image').style.opacity = "0";
              }
              nerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>
                Point Cloud Semantic Mapping 
              </papertitle>
            <br>
      <em>Spring 2023</em>
            <!-- <br>
            Video:<a href="https://youtu.be/2mXXd_wS-Yo"> Link</a> -->
            <br>
            Code:<a href="https://github.com/swagholikar29/Point-Cloud-Semantic-Mapping"> GitHub</a>
            <p></p>
            <p> In this project, sensor fusion of LiDAR and camera was carried out on the Kitti dataset to obtain painted pointcloud.<br>
              LiDAR pointcloud was projected on the images. Pointcloud segmentation is carried out on the images and 
              each corresponding point in the pointcloud is classified and painted.
              ICP registration trials using Open3d are carried out to merge the pointclouds to obtain 3D reconstruction of the scene. 
              Finally, for each pointcloud, the Bird's eye view is also obtained.
                <br>
            </p>
          </td>
        </tr>

         <!-- Panoptic Segmentation -->

         <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/panoptic.png' width="220" height="220">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Panoptic Segmentation</papertitle>
              <br>
              <em>Fall</em> 2022
<!--               <br> -->
<!--               Code:<a href="https://github.com/rohiitb/semantic_mapping_icp"> Github</a> -->
              
              <br>
              Report:<a href="data/CS541_Deep_Learning_Report.pdf"> Link</a>

              <br>
              Code:<a href="https://github.com/swagholikar29/Panoptic-Segmentation"> GitHub</a>
              <p>Panoptic segmentation was done on SemanticKITTI dataset (3D LiDAR Point Cloud Data) which combines the outputs of semantic segmentation and instance
                segmentation for Deep Learning under Prof. Fabricio Murai. 
                
                <br> 
                In this project, Shared encoder-decoder backbone was used to combine these two
                tasks. RangeNet++ was used for semantic segmentation, mask R-CNN for instance segmentation and implemented in TensorFlow 2.0 with novel parameter free panoptic head.
              </p>
            </td>
          </tr>    
          

         
          <!-- Path Planning of Non-holonomic Robots -->

         <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  
          <td style="padding:20px;width:30%;vertical-align:middle">
           <div class="one">
               <img src='images/warehouse.gif' width="200" height="210">
           </div>

            <script type="text/javascript">
              function nerf_start() {
                document.getElementById('nerf_image').style.opacity = "1";
              }

              function nerf_stop() {
                document.getElementById('nerf_image').style.opacity = "0";
              }
              nerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>
                Path Planning of Non-holonomic Robots 
              </papertitle>
            <br>
      <em>Spring 2023</em>
            <br>
            Report:<a href="data/real_time_optimal_path_planning_of_non_holonomic_robots_final.pdf"> Link</a>
        <!--    <br> -->
            <br>
        <!--Report:<a href="data/proj_report.pdf"> Link</a>
            <br>
            Video:<a href="https://youtu.be/hxh-_XgXjow"> Link</a>
            <br> -->
            Code:<a href="https://github.com/swagholikar29/Real-Time-Optimal-Path-Planning-of-Non-Holonomic-Robots"> GitHub</a>
            <p></p>
            <p> In this project, I have planned path traversal for non-holonomic robots by state-of-the-art algorithms.
              <br>
                For global path planning, I have used the most recent algorithms like AIT* and BIT*. These are the latest variants of Informed RRT*. 
              <br>
                For local path planning and path traversal, APF and MPC are used. Evaluation is done based on time-complexity and accuracy of optimal path detection+traversal.
                <br>
            </p>
          </td>
        </tr>

        <!-- Embedded Deep Learning Projects -->

        <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  
          <td style="padding:20px;width:30%;vertical-align:middle">
           <div class="one">
               <img src='images/deep_learning.gif' width="200" height="210">
           </div>

            <script type="text/javascript">
              function nerf_start() {
                document.getElementById('nerf_image').style.opacity = "1";
              }

              function nerf_stop() {
                document.getElementById('nerf_image').style.opacity = "0";
              }
              nerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>
                Embedded Deep Learning Projects 
              </papertitle>
            <br>
      <em>Spring 2023</em>
            <!-- <br> -->
            <!-- BERT:<a href="data/2. Text_Classification_using_BERT_Embeddings_Solution_ver03.ipynb"> Link</a> -->
            <!-- <br> -->
            <!-- YOLO:<a href="data/YOLO.ipynb"> Link</a> -->
            <br>
            P&Q:<a href="data/swagholikar_assignemnet_1_on_device_DL.ipynb"> Link</a>
            <br>
            NAS:<a href="data/swagholikar_assignemnet_2_on_device_DL.ipynb"> Link</a>
            <br>
            DIS:<a href="https://github.com/swagholikar29/Dynamic-Network-Inference"> Link</a>
        <!--    <br> -->
            <br>
        <!--Report:<a href="data/proj_report.pdf"> Link</a>
            <br>
            Video:<a href="https://youtu.be/hxh-_XgXjow"> Link</a>
            <br> -->
            Code:<a href="https://github.com/swagholikar29/Deep-Learning-Projects"> GitHub</a>
            <br>
            Code: <a href="https://github.com/swagholikar29/Text-Classification-using-BERT-Embeddings"> GitHub</a>
            <p></p>
            <p> These projects include Neural Networks Design from Scratch, Neural Machine Translation.
              <br>
                Also, use of BERT Embeddings, Higher Level APIs, Design of Optimizers from Scratch in Numpy. 
              <br>
                Pruning & Quantization, Neural Architecture Search, Dynamic Network Inference.
                <br>
            </p>
          </td>
        </tr> 
            

           
          
        <!-- 3D Reconstruction from images -->

          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  
            <td style="padding:20px;width:30%;vertical-align:middle">
             <div class="one">
                 <img src='images/sfm.png' width="220" height="160">
             </div>

              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>
                  3D Reconstruction from images 
                </papertitle>
              <br>
        <em>Summer 2023</em>
              <br>
              Code:<a href="https://github.com/swagholikar29/3D-Reconstruction-from-images"> Github</a>
              <p></p>
              <p> Simultaneously reconstructed 3D scene Mapping and extracted camera pose Localization from given stereo camera
                correspondences using Non-Linear triangulation, Non-Linear PnP and Bundle Adjustment (BA) pipeline.
                  <br>
              </p>
            </td>
          </tr> 

  
          <!-- Boundary Detection -->
  
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/pblite.png' width="200" height="200">
                        </div>
                        <script type="text/javascript">
                          function nerf_start() {
                            document.getElementById('nerf_image').style.opacity = "1";
                          }

                          function nerf_stop() {
                            document.getElementById('nerf_image').style.opacity = "0";
                          }
                          nerf_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Boundary Detection
                          </papertitle>
                        <br>
                      <em>Spring 2023</em>
                        <br>
                        Code:<a href="https://github.com/swagholikar29/Pb-Probability-of-Boundary-Lite-Boundary-Detection"> GitHub</a>
                        <p></p>
                        <p>
                          In this project, Detected edges in image using probability based boundary detection using K-means clustering of Oriented DoG (ODoG),
                          Leung-Malik (LM) and Gabor Filter bank responses. Outperformed the results from classical canny and sobel filters.<br>
                            <br>
                        </p>
                      </td>
                    </tr>
          
          
          <!-- Auto Calib -->
  
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/calibration-patterns.gif' width="200" height="200">
                        </div>
                        <script type="text/javascript">
                          function nerf_start() {
                            document.getElementById('nerf_image').style.opacity = "1";
                          }

                          function nerf_stop() {
                            document.getElementById('nerf_image').style.opacity = "0";
                          }
                          nerf_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Auto Calib: Camera Calibration
                          </papertitle>
                        <br>
                      <em>Spring 2023</em>
                      <!--  <br>
                        Report:<a href="data/mpc_manipulator_report.pdf"> Link</a> -->
                        <br>
                        Code:<a href="https://github.com/swagholikar29/Camera-Calibration"> GitHub</a>
                        <p></p>
                        <p>
                            In this project, I implemented research work presented by Zhengyou Zhang for Calibrating a Camera which is one of the hallmark papers in
                            camera calibration. Estimated parameters of the camera like the focal length, distortion coefficients and principle point.  
                            <br>
                        </p>
                      </td>
                    </tr>

          
          <!-- Complex Highway Navigation -->
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
            <td style="padding:20px;width:25%;vertical-align:middle">
             <div class="one">
               <img src='images/rl.gif' width="270" height="200">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Complex Highway Navigation</papertitle>
              <br>
                <em>Spring 2023</em>
                <br>
              Report:<a href="data/RL_Project_Report.pdf"> Link</a>
              
                <br>
              Code:<a href="https://github.com/swagholikar29/Navigating-Complex-Highway-Scenarios-with-Advanced-RL-techniques-in-Highway-Env"> Github</a>
              <p></p>
              <p>
                  In this project, we Implemented discrete action space algorithms such as DQN, DQN-MR and DQN-PER on OpenAI Gym’s Third party
                  environment, Highway-env. Compared training time and accuracy to discover DQN-PER has the best performance.
                <br>
              </p>
            </td>
          </tr>

          <!-- 3D Trajectory Tracking -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/drone.gif' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>3D Trajectory Tracking (Sliding Mode Control)</papertitle>
              <br>
                <em>Spring</em> 2023
              <br>
                Code:<a href="https://github.com/swagholikar29/Sliding-Mode-Control-Based-3D-Trajectory-Tracking-for-UAVs"> GitHub</a>
              <p></p>
              <p>Designed and deployed Sliding Mode Controllers for trajectory tracking for micro UAVs, with an acceptable error range of
                1% while countering environmental noise. Generated a fifth-order trajectory with an accuracy of 0.03% for path planning. </p>
            </td>
          </tr>

          <!-- Motion Planning Projects -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/motion_planning.gif' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Motion Planning Projects</papertitle>
              <br>
                <em>Spring</em> 2023
              <br>
                Code:<a href="https://github.com/swagholikar29/Motion_Planning_Projects"> GitHub</a>
              <p></p>
              <p>This project implements various search based planners (Dijsktra, A star, D star) and sampling-based planners(RRT, RRT star and Informed RRT star).The planners are implemented on a 2d map. </p>
            </td>
          </tr>

          <!-- Reinforcement Learning Projects -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/reinforcement_learning.gif' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Reinforcement Learning Projects</papertitle>
              <br>
                <em>Spring</em> 2023
              <br>
                Code:<a href="https://github.com/swagholikar29/Reinforcement_Learning_Projects"> GitHub</a>
              <p></p>
              <p>These projects include implementation of Epsilon-Greedy Algorithm, Dynamic Programming, Monte Carlo, Temporal Difference Learning, Model-based RL</p>
            </td>
          </tr>

           <!--         Path Planning of Continuum Robots -->

           <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"> 
            <td style="padding:20px;width:30%;vertical-align:middle">
             <div class="one">
                 <img src='images/concentric_tubes.png' width="200" height="200">
             </div>
              
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>
               Path Planning of Continuum Robots 
               </papertitle>
              <br>
        <em>Fall 2022</em>
              <br>                       
             Code:<a href="https://github.com/swagholikar29/Path-Planning-of-Biomedical-Concentric-Tube-Continuum-Robots"> GitHub</a>
              <p></p>
              <p>
              In this project, I reconstructed informed RRT algorithm for path planning of continuum robots which are needle sized manipulators used in
              image-guided surgical procedures resulted in accurately generating optimal and feasible path in a dynamic environment..
              <br>
              <br>
              <!--Mask RCNN is a a conceptually simple, flexible, and general framework for object instance segmentation.It extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. This pipeline was implemented to do per pixel object detection and the corresponding mask.-->
              <br>
              </p>
            </td>
          </tr>
 
          <!-- YOLO -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/yolo.JPG' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>YOLO (Object Detection)</papertitle>
              <br>
                <em>Fall</em> 2022
              <br>
                Code:<a href="https://github.com/swagholikar29/Real-time-Multi-Object-Detection-using-YOLO-algorithm"> GitHub</a>
              <p></p>
              <p>Implemented YOLO pipeline from scratch to do object detection on street scene images. <br>MAP acheived : 0.43</p>
            </td>
          </tr>
          
          <!-- Autonomous Battle Bot -->
      <!--    <tr onmouseout="loss_stop()" onmouseover="loss_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/pic2.jpg' width="200" height="220">
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }

                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Autonomous Battle Bot</papertitle>
              <br>
              <em>Fall</em> 2021
              <br>
              Code: <a href="https://github.com/rohiitb/Autonomous_Battle_bot">Github</a>
              <p></p>
              <p>
                Designed and fabricated a 2-wheel differential drive robot with a gripper arm capable of grabbing cans and also detect light of desired frequencies.<br>
                Robot was also capable of navigating itself to a particular location using VIVE localization system.<br>
                ESP32 microcontroller was used for controlling and grabbing.<br>
                Wireless communication via HTML(Webpage) and UDP was used to send commands to the robot.
              </p>
            </td>
          </tr>

        </tbody></table>  -->
        
                <br><br><br>                <br><br><br>  


        
        
    <!--         Experience starts here-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <br>
                <br>
                <heading>Previous Education</heading>
              </td>
            </tr>
          </tbody>
        </table>
        <br>

  
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>University of Pune</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                August 2016 - October 2020
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Bachelor of Technology</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 9.32/10.0
              </td>              
            </tr>
          </tbody>
        </table>
    <!--    <b><u>Leadership Experience</u> : Team Taurus (Gokarting team, Pune University)</b>
        <ul>
          <li>Led a team of 20 members to design and manufacture a go-kart. Team comprised of different subsystems - Chassis, Engine and Transmission, Brake, Steering, Electrical. 
            A go-kart was manufactured from scratch using 125cc bike engine. All the components were designed optimally with considering factor of safety as well as weight.</li>
          <li>Achieved 3rd place in International Series of karting, 1st place in Kart Design Championship (Also won Best Design Award and Lightest kart) and 4th place in Indian karting championship. </li>
        </ul>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>  -->
<!--               <td style="paddi0px;width:50%;vrtical-align:middle"> -->
 <!--                           <td align = "center">

                <img src="./images/kdc.PNG" width="250" height="200">
              </td> -->
<!--               <td style="paddi0px;width:50%;vrtical-align:middle"> -->
<!--             <td align = "center">
                <img src="./images/ikc.jpeg" width="350" height="200">
              </td>              
            </tr>
            <tr>
              <td align = "center">
                <papertitle>KDC 2019</papertitle>
              </td>
              <td align = "center">
                <papertitle>IKC 2019</papertitle>
              </td>              
            </tr>
          </tbody>
        </table>
        
                        <br><br>  -->

  
  <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <br>
                <br>
                <papertitle>Atlas Copco GECIA</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                <br>
                <br>
                November 2020 - July 2022
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Design & Development Engineer</papertitle>
              </td> 
              <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 3.75/4.0
              </td>               
            </tr>
          </tbody>
        </table>
        <ul>
          <li>Design of Engineered Oil-free compressors keeping standards , application , cost and safety into consideration. </li>
          <li>Extensive support to product company for customized 3D models, 2D, bill of materials , P&ID, Assembly instructions etc. </li>
          <li>Co-ordinated with cross-functional teams like PM, Electrical, production and quality to deliver timely output. </li>
          <li>Assisted Robotics Process Automation (RPA) team to automate the repetitive tasks in customized design process. </li>
        </ul> 
                                <br><br> --> 
                              

  
  <!--
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Aespaes Labs Pvt Ltd</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                August 2020 - November 2020
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Artificial Intelligence Intern</papertitle>
              </td> -->
<!--               <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 3.75/4.0
              </td>               -->
<!--           </tr>
          </tbody>
        </table>
        <ul>
          <li>Deployed Augmented Reality project on Production Line of Bajaj Auto Ltd. by augmenting a blind spot at welding station on
            screen which helped workers to carry out welding operation with finesse.  </li>
          <li>Responsible for development and content mapping of VR Labs in Ed-tech. </li>
        </ul>
        
                        <br><br>  -->

  
<!--    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Automotive Research Association of India</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                July 2019 - December 2020
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Project Intern (Structural Dynamics Lab)</papertitle>
              </td> -->
<!--               <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 3.75/4.0
              </td>               -->
<!--         </tr>
          </tbody>
        </table>
        <ul>
          <li>Designed and drafted fixtures required for testing of automotive components including truck axles, railway chassis. </li>
          <li>Assisted in performing wide range of component testing such as durability, fatigue, vibration, static structural tests. </li>
          <li>Contributed in designing components for test equipment. </li>
        </ul>   -->

        
        <br><br><br>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                    Great thanks to Jon for his amazing <a href="https://jonbarron.info/">website template</a>!

              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  


</body>

</html>
