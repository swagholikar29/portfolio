<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Swapneel Wagholikar</title>
  
  <meta name="author" content="Swapneel Wagholikar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/wpi_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:43%;vertical-align:middle">
              <p style="text-align:center">
                <name>Swapneel Wagholikar</name>
              </p>
              <p> I'm a graduate student at <a href="https://www.wpi.edu/academics/departments/robotics-engineering">Worcester Polytechnic Institute</a> majoring in Robotics Engineering. I have had the opportunity to be a part of multiple projects affiliated to <a href="https://zhang-vislab.github.io/">VISLab</a> robotics lab at WPI. I work at the intersection of Perception, Deep learning, Motion Planning and embedded systems.<br>
                <br>
<!--                 My passion for robotics stems from my love for building and bringing things to life, and I am excited to continue exploring the possibilities in this field.  -->
<!--                 <br> -->
                  At WPI, I am currently working on Directed research, where I am advised by <a href="https://zhang-vislab.github.io/">Prof. Ziming Zhang</a> for implementation of PointAttN: Tranformer Network for Point Cloud Completion which aims to pay attention to the relationships between points without dividing shapes into smaller regions. 
                <br><br>
                In addition to that, I have completed my Summer 2023 internship at <a href="https://www.linkedin.com/company/void-robotics/">Void Robotics</a> where I worked on ZED2/GNSS Odometry Fusion and for Fall 2023, I have joined <a href="http://www.dekaresearch.com/">DEKA Research and Development</a> as a Robotics Intern (Perception) where I am working on Sentry bot to create accurate ground truth depth maps through sensor fusion and classical computer vision.
                <br><br>
                I am actively looking for internship/job opportunities in Computer Vision, Deep Learning and Robotics Software industry. I believe that diversity can bring up new perspectives and will spark brilliant ideas. I look forward to learning with experts in academia and industry. Please feel free to reach out to me at <a href="swagholikar@wpi.edu">swagholikar@wpi.edu</a> <br>
                Please feel free to connect with me with any questions regarding my work.<br><br>
                Connect with me on <a href="https://www.linkedin.com/in/swapneel-wagholikar-96017515a/">LinkedIn</a>.
                
              </p>
              <p style="text-align:center">
                Email  &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp 
                Resume &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp 
                GitHub
              </p>
              <p style="text-align:center">
                
                <a href="mailto:swagholikar@wpi.edu"><img width="50" height="50" alt="mail icon" src="images/mail_icon.png" class="hoverZoomLink"></a> &nbsp &nbsp &nbsp &nbsp &nbsp
                <a href="data/Swapneel_Wagholikar_Resume.pdf"><img width="50" height="50" alt="resume icon" src="images/res_icon.png" class="hoverZoomLink"></a> &nbsp &nbsp &nbsp &nbsp &nbsp
                <a href="https://github.com/swagholikar29"><img width="50" height="50" alt="git icon" src="images/git_icon.png" class="hoverZoomLink"></a> 
              </p>
<!--               <p style="text-align:center">
                <a href="mailto:rbhikulej@seas.upenn.edu">Email</a> &nbsp/&nbsp
                <a href="data/Swapneel_Wagholikar_Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/rohiitb">github</a> &nbsp
              </p> -->
            </td>
            <td style="padding:2.5%;width:100%;max-width:120%">
              <a href="images/profile_pic1.jpg"><img style="width:100%;max-width:150%" alt="profile photo" src="images/profile_pic1.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        
<!--         Education starts here-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <heading>Education</heading>
              </td>
            </tr>
          </tbody>
        </table>
        <br>
        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Worcester Polytechnic Institute</papertitle> (Worcester, MA)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                August 2022 - May 2024 (Expected)
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Master of Science in Robotics Engineering</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 4.0/4.0
              </td>              
            </tr>
          </tbody>
        </table>
        <b><u>Topics of Interest</u> : </b>Computer Vision, Machine Perception, Camera calibration, Multi-sensor Fusion, Neural architectures, Deep Learning, Motion Planning, Navigation, Robotics.
        <ul style="margin-top:0px;">
          <li>Teaching Assistant for MA 1022 : Calculus II (Fall 2022)</li>
          <li>Teaching Assistant for MA 1024 : Calculus IV (Spring 2023)</li>
       <!--   <li>Teaching Assistant for MEAM 211 : Engineering Physics (Dynamics) (Spring 2022, Spring 2023)</li>   -->
        </ul>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <b><u>Research Experience</u> : </b> VISLab
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                May 2023 - August 2023
              </td>              
            </tr>
          </tbody>
        </table>

        
<!--         <b><u>Research Experience</u> : </b> mLAB (GRASP) -->
        <ul style="margin-top:0px;">
          <li>Implementated PointAttN: a Tranformer Network for Point Cloud Completion. </li>
          <li>Experimented with the Geometric Details Perceptron (GDP) and Self Feature Augment (SFA) blocks in encoder.</li>
          <li>Network paid attention to the relationsships between points without dividing shapes into smaller regions.</li>
          <li>Implemented cross layer information integration in the PointAttN Network and enhanced the baseline results by 20%.</li>
        </ul>

<!--         Internship Experience starts here-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <heading>Internship Experience</heading>
              </td>
            </tr>
          </tbody>
        </table>
        <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>DEKA Research and Development</papertitle> (Manchester, NH)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                September 2023 - Ongoing
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Robotics Intern (Perception)</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
              <!--  GPA : 4.0/4.0 -->
              </td>              
            </tr>
          </tbody>
        </table>
        <!-- <b><u>Topics of Interest</u> : </b>Computer Vision, Machine Perception, Camera calibration, Multi-sensor Fusion, Neural architectures, Deep Learning, Motion Planning. -->
        <ul style="margin-top:0px;">
          <li>Working on Sentry bot to create high-quality depth maps through sensor fusion and classical computer vision techniques.</li>
          <li>Developing software for real-time data integration from Velodyne’s LiDAR and a pair of Long Range RGB cameras.</li>
          <li>Enhancing depth estimation CNN architecture aiming to predict the probability of terrain traversability accuarately.</li>
        <!--   <li>Teaching Assistant for MEAM 211 : Engineering Physics (Dynamics) (Spring 2022, Spring 2023)</li>   -->
        </ul>

        <br><br>


        <!-- Void Internship -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Void Robotics</papertitle> (Marathon, FL)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                May 2023 - August 2023
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Robotics Software Intern (Perception, Navigation)</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
              <!--  GPA : 4.0/4.0 -->
              </td>              
            </tr>
          </tbody>
        </table>
        <!-- <b><u>Topics of Interest</u> : </b>Computer Vision, Machine Perception, Camera calibration, Multi-sensor Fusion, Neural architectures, Deep Learning, Motion Planning. -->
        <ul style="margin-top:0px;">
          <li>Worked on ZED2/GNSS Odometry Fusion to get an accurate position of the voidwalking bot. The final odometry integrated RTK GPS + Visual Odometry + IMU. Enabled the bot to walk GPS and ZED2 within an accuracy of 1cm.</li>
          <li>Autumated test cases in ROS2 for line rendering in RVIZ via calling the sevice through rqt.</li>
          <li>Constructed a Docker-integrated ROS package for SLAM on the environment resulting in a 15% productivity boost.</li>
        <!--   <li>Teaching Assistant for MEAM 211 : Engineering Physics (Dynamics) (Spring 2022, Spring 2023)</li>   -->
        </ul>

        <br><br>

        <!-- Aespaes Internship -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Aespaes Labs Pvt. Ltd.</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                May 2020 - Nov 2020
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>AI Intern (Computer Vision)</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
              <!--  GPA : 4.0/4.0 -->
              </td>              
            </tr>
          </tbody>
        </table>
        <!-- <b><u>Topics of Interest</u> : </b>Computer Vision, Machine Perception, Camera calibration, Multi-sensor Fusion, Neural architectures, Deep Learning, Motion Planning. -->
        <ul style="margin-top:0px;">
          <li>Developed a deep learning pipeline for detection of O-ring in Camshaft and classification of Camshaft based on presence/absense of O-ring. Project deployed on the production line of Bajaj Auto Pvt. Ltd. Pune for inspection purposes.</li>
          <li>Augmented Reality using OpenCV to augment the blind spot at welding station for same manufacturing plant.</li>
          <li>Prototyped and proposed VR Lab to AIM Laboratory of WPI for experimentation in Biomedical Robotics Research.</li>
        <!--   <li>Teaching Assistant for MEAM 211 : Engineering Physics (Dynamics) (Spring 2022, Spring 2023)</li>   -->
        </ul>

        <br><br>
        
             
        <!-- Projects start here !-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <heading>Projects</heading>
              </td>
            </tr>
          </tbody>
        </table>
        
        
        <table style="width:130%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         
         <!-- Mobile NeRF -->

         <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/lego.gif' width="220" height="220">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Mobile NeRF</papertitle>
            <br>
            <em>Fall</em> 2023 (Ongoing)
<!--               <br> -->
<!--               Code:<a href="https://github.com/rohiitb/semantic_mapping_icp"> Github</a> -->
            
            <!-- <br> -->
            <!-- Report:<a href="data/CS541_Deep_Learning_Report.pdf"> Link</a> -->

            <!-- <br> -->
            <!-- Code:<a href="https://github.com/swagholikar29/Panoptic-Segmentation"> GitHub</a> -->
            <p>Optimizing a NeRF (Neural Radience Field) based 3D reconstruction model, with techniques such as model pruning and quantization, and
              planning to deploy it on Android, demonstrating proficiency in on-device deep learning for real-time 3D reconstruction. 
              
              <br> 
              Guide: Prof. Bashima Islam
            </p>
          </td>
        </tr>
         
         <!-- Panoptic Segmentation -->

         <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/panoptic.png' width="220" height="220">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Panoptic Segmentation</papertitle>
              <br>
              <em>Fall</em> 2022
<!--               <br> -->
<!--               Code:<a href="https://github.com/rohiitb/semantic_mapping_icp"> Github</a> -->
              
              <br>
              Report:<a href="data/CS541_Deep_Learning_Report.pdf"> Link</a>

              <br>
              Code:<a href="https://github.com/swagholikar29/Panoptic-Segmentation"> GitHub</a>
              <p>Panoptic segmentation was done on SemanticKITTI dataset (3D LiDAR Point Cloud Data) which combines the outputs of semantic segmentation and instance
                segmentation for Deep Learning under Prof. Fabricio Murai. 
                
                <br> 
                In this project, Shared encoder-decoder backbone was used to combine these two
                tasks. RangeNet++ was used for semantic segmentation, mask R-CNN for instance segmentation and implemented in TensorFlow 2.0 with novel parameter free panoptic head.
              </p>
            </td>
          </tr>    
         
         
          <!-- Path Planning of Non-holonomic Robots -->

         <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  
          <td style="padding:20px;width:30%;vertical-align:middle">
           <div class="one">
               <img src='images/warehouse.gif' width="200" height="210">
           </div>

            <script type="text/javascript">
              function nerf_start() {
                document.getElementById('nerf_image').style.opacity = "1";
              }

              function nerf_stop() {
                document.getElementById('nerf_image').style.opacity = "0";
              }
              nerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>
                Path Planning of Non-holonomic Robots 
              </papertitle>
            <br>
      <em>Spring 2023</em>
            <br>
            Report:<a href="data/real_time_optimal_path_planning_of_non_holonomic_robots_final.pdf"> Link</a>
        <!--    <br> -->
            <br>
        <!--Report:<a href="data/proj_report.pdf"> Link</a>
            <br>
            Video:<a href="https://youtu.be/hxh-_XgXjow"> Link</a>
            <br> -->
            Code:<a href="https://github.com/swagholikar29/Real-Time-Optimal-Path-Planning-of-Non-Holonomic-Robots"> GitHub</a>
            <p></p>
            <p> In this project, I have planned path traversal for non-holonomic robots by state-of-the-art algorithms.
              <br>
                For global path planning, I have used the most recent algorithms like AIT* and BIT*. These are the latest variants of Informed RRT*. 
              <br>
                For local path planning and path traversal, APF and MPC are used. Evaluation is done based on time-complexity and accuracy of optimal path detection+traversal.
                <br>
            </p>
          </td>
        </tr>
        
         <!-- Point Cloud Semantic Mapping -->

          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  
            <td style="padding:20px;width:30%;vertical-align:middle">
             <div class="one">
                 <img src='images/seg_combined_gif.gif' width="180" height="200">
             </div>

              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>
                  Point Cloud Semantic Mapping 
                </papertitle>
              <br>
        <em>Spring 2023</em>
              <!-- <br>
              Video:<a href="https://youtu.be/2mXXd_wS-Yo"> Link</a> -->
              <br>
              Code:<a href="https://github.com/swagholikar29/Point-Cloud-Semantic-Mapping"> GitHub</a>
              <p></p>
              <p> In this project, sensor fusion of LiDAR and camera was carried out on the Kitti dataset to obtain painted pointcloud.<br>
                LiDAR pointcloud was projected on the images. Pointcloud segmentation is carried out on the images and 
                each corresponding point in the pointcloud is classified and painted.
                ICP registration trials using Open3d are carried out to merge the pointclouds to obtain 3D reconstruction of the scene. 
                Finally, for each pointcloud, the Bird's eye view is also obtained.
                  <br>
              </p>
            </td>
          </tr> 
            

           
          
        <!-- 3D Reconstruction from images -->

          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  
            <td style="padding:20px;width:30%;vertical-align:middle">
             <div class="one">
                 <img src='images/sfm.png' width="220" height="160">
             </div>

              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>
                  3D Reconstruction from images 
                </papertitle>
              <br>
        <em>Summer 2023</em>
              <br>
              Code:<a href="https://github.com/swagholikar29/3D-Reconstruction-from-images"> Github</a>
              <p></p>
              <p> Simultaneously reconstructed 3D scene Mapping and extracted camera pose Localization from given stereo camera
                correspondences using Non-Linear triangulation, Non-Linear PnP and Bundle Adjustment (BA) pipeline.
                  <br>
              </p>
            </td>
          </tr> 

          
          <!-- F1 tenth -->

<!--          <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/race.gif' width="220" height="220">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://f1tenth.org/">
                <papertitle>F1tenth Racing (UPenn ESE 615 Autonomous Racing)</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/shivangimisra1/">Shivangi Misra</a>,
              <strong>Dingding Zheng</strong>,
              <a href="https://weiyi-tang.netlify.app/">Weiyi Tang</a>
              <br>
              <em>Spring</em> 2020
              <br>
              <a href="https://f1tenth.org/">project page</a> /
              
              <a href="data/ESE_615_Final_Report_by_Team_1.pdf">report</a>/

              <a href="https://github.com/zddkjmuner/Autonomous-Racing">code</a>
              <p></p>
              <p><a href="https://f1tenth.org/build.html">”F1tenth”</a> is an open-source, small-scale racing car platform
                widely used for teaching and research in safe autonomy.
                Maneuvering a racing car to finish loops in minimum time
                has been studied for decades. However, it’s always computationally
                expensive and infeasible to solve this problem by
                real-time trajectory planning. In this project, we generated
                a velocity profile to find the maximum permissible speed of
                racing car on each waypoint on the path. Then, we use CMAES
                (Covariance Matrix Adaptation - Evolution Strategy) to
                generate the desired path for vehicle to track. The generated
                path has a relatively small curvature which allows the racing
                car to run at high, steady speed. Pure pursuit is used as
                the vehicle controller. To avoid obstacles, we implemented
                ODG-PFM (Obstacle-Dependent Gaussian Potential
                Field) and compared its performance VS. RRT*. In order to
                measure the performance of these two algorithms, we setup
                several testing maps and added noise to the environment.
              </p>
            </td>
          </tr>    -->

  
          <!-- Boundary Detection -->
  
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/pblite.png' width="200" height="200">
                        </div>
                        <script type="text/javascript">
                          function nerf_start() {
                            document.getElementById('nerf_image').style.opacity = "1";
                          }

                          function nerf_stop() {
                            document.getElementById('nerf_image').style.opacity = "0";
                          }
                          nerf_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Boundary Detection
                          </papertitle>
                        <br>
                      <em>Spring 2023</em>
                        <br>
                        Code:<a href="https://github.com/swagholikar29/Pb-Probability-of-Boundary-Lite-Boundary-Detection"> GitHub</a>
                        <p></p>
                        <p>
                          In this project, Detected edges in image using probability based boundary detection using K-means clustering of Oriented DoG (ODoG),
                          Leung-Malik (LM) and Gabor Filter bank responses. Outperformed the results from classical canny and sobel filters.<br>
                            <br>
                        </p>
                      </td>
                    </tr>
          
          
          <!-- Auto Calib -->
  
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/calibration-patterns.gif' width="200" height="200">
                        </div>
                        <script type="text/javascript">
                          function nerf_start() {
                            document.getElementById('nerf_image').style.opacity = "1";
                          }

                          function nerf_stop() {
                            document.getElementById('nerf_image').style.opacity = "0";
                          }
                          nerf_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Auto Calib: Camera Calibration
                          </papertitle>
                        <br>
                      <em>Spring 2023</em>
                      <!--  <br>
                        Report:<a href="data/mpc_manipulator_report.pdf"> Link</a> -->
                        <br>
                        Code:<a href="https://github.com/swagholikar29/Camera-Calibration"> GitHub</a>
                        <p></p>
                        <p>
                            In this project, I implemented research work presented by Zhengyou Zhang for Calibrating a Camera which is one of the hallmark papers in
                            camera calibration. Estimated parameters of the camera like the focal length, distortion coefficients and principle point.  
                            <br>
                        </p>
                      </td>
                    </tr>

          
          <!-- Complex Highway Navigation -->
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">  <!--bgcolor="#ffffd0"-->
            <td style="padding:20px;width:25%;vertical-align:middle">
             <div class="one">
               <img src='images/rl.gif' width="270" height="200">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Complex Highway Navigation</papertitle>
              <br>
                <em>Spring 2023</em>
                <br>
              Report:<a href="data/RL_Project_Report.pdf"> Link</a>
              
                <br>
              Code:<a href="https://github.com/swagholikar29/Navigating-Complex-Highway-Scenarios-with-Advanced-RL-techniques-in-Highway-Env"> Github</a>
              <p></p>
              <p>
                  In this project, we Implemented discrete action space algorithms such as DQN, DQN-MR and DQN-PER on OpenAI Gym’s Third party
                  environment, Highway-env. Compared training time and accuracy to discover DQN-PER has the best performance.
                <br>
              </p>
            </td>
          </tr>

           <!--         Path Planning of Continuum Robots -->

                   <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"> 
                     <td style="padding:20px;width:30%;vertical-align:middle">
                      <div class="one">
                          <img src='images/concentric_tubes.png' width="200" height="200">
                      </div>
                       
                       <script type="text/javascript">
                         function nerf_start() {
                           document.getElementById('nerf_image').style.opacity = "1";
                         }

                         function nerf_stop() {
                           document.getElementById('nerf_image').style.opacity = "0";
                         }
                         nerf_stop()
                       </script>
                     </td>
                     
                     
                     <td style="padding:20px;width:75%;vertical-align:middle">
                       <papertitle>
                        Path Planning of Continuum Robots 
                        </papertitle>
                       <br>
                 <em>Fall 2022</em>
                       <br>                       
                      Code:<a href="https://github.com/swagholikar29/Path-Planning-of-Biomedical-Concentric-Tube-Continuum-Robots"> GitHub</a>
                       <p></p>
                       <p>
                       In this project, I reconstructed informed RRT algorithm for path planning of continuum robots which are needle sized manipulators used in
                       image-guided surgical procedures resulted in accurately generating optimal and feasible path in a dynamic environment..
                       <br>
                       <br>
                       <!--Mask RCNN is a a conceptually simple, flexible, and general framework for object instance segmentation.It extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. This pipeline was implemented to do per pixel object detection and the corresponding mask.-->
                       <br>
                       </p>
                     </td>
                   </tr>
          
          <!-- YOLO -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/yolo.JPG' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>YOLO (Object Detection)</papertitle>
              <br>
                <em>Fall</em> 2022
              <br>
                Code:<a href="https://github.com/swagholikar29/Real-time-Multi-Object-Detection-using-YOLO-algorithm"> GitHub</a>
              <p></p>
              <p>Implemented YOLO pipeline from scratch to do object detection on street scene images. <br>MAP acheived : 0.43</p>
            </td>
          </tr>

          <!-- 3D Trajectory Tracking -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/control.png' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>3D Trajectory Tracking (Sliding Mode Control)</papertitle>
              <br>
                <em>Spring</em> 2023
              <br>
                Code:<a href="https://github.com/swagholikar29/Sliding-Mode-Control-Based-3D-Trajectory-Tracking-for-UAVs"> GitHub</a>
              <p></p>
              <p>Designed and deployed Sliding Mode Controllers for trajectory tracking for micro UAVs, with an acceptable error range of
                1% while countering environmental noise. Generated a fifth-order trajectory with an accuracy of 0.03% for path planning. </p>
            </td>
          </tr>

          <!-- Motion Planning Projects -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Infomed_RRT_star.png' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Motion Planning Projects</papertitle>
              <br>
                <em>Spring</em> 2023
              <br>
                Code:<a href="https://github.com/swagholikar29/Motion_Planning_Projects"> GitHub</a>
              <p></p>
              <p>This project implements various search based planners (Dijsktra, A star, D star) and sampling-based planners(RRT, RRT star and Informed RRT star).The planners are implemented on a 2d map. </p>
            </td>
          </tr>

          <!-- Deep Learning Projects -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/dl.png' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Deep Learning Projects</papertitle>
              <br>
                <em>Fall</em> 2022
              <br>
                Code:<a href="https://github.com/swagholikar29/Deep-Learning-Projects"> GitHub</a>
              <p></p>
              <p>These projects include Neural Networks Design from Scratch, Neural Machine Translation, use of BERT Embeddings, Higher Level APIs, Design of Optimizers from Scratch in Numpy. </p>
            </td>
          </tr>

          <!-- Reinforcement Learning Projects -->

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/rl.png' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Reinforcement Learning Projects</papertitle>
              <br>
                <em>Spring</em> 2023
              <br>
                Code:<a href="https://github.com/swagholikar29/Reinforcement_Learning_Projects"> GitHub</a>
              <p></p>
              <p>These projects include implementation of Epsilon-Greedy Algorithm, Dynamic Programming, Monte Carlo, Temporal Difference Learning, Model-based RL</p>
            </td>
          </tr>
          
          <!-- SOLO -->

    <!--      <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/first1.png' width="190">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>SOLO (Instance Segmentation)</papertitle>
              <br>
                <em>Fall</em> 2022
              <br>
                Code:<a href="https://github.com/rohiitb/SOLO_Instance_segmentation"> Github</a>
              <p></p>
              <p>Implemented a single-stage instance segmentation pipeline "Segmenting Objects by Location" based on Feature pyramid network model to classify and generate masks for objects belonging to 3 categories: Animals, Vehicles and Humans.</p>
            </td>
          </tr> -->
          
          

            <!-- 3D Reconstruction from images -->
      <!--      <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
              <td style="padding:30px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/recon_gif.gif' width="200" height="160">
                </div>
                <script type="text/javascript">
                  function dpzlearn_start() {
                    document.getElementById('dpzlearn_image').style.opacity = "1";
                  }

                  function dpzlearn_stop() {
                    document.getElementById('dpzlearn_image').style.opacity = "0";
                  }
                  dpzlearn_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
            
                  <papertitle>3D Reconstruction from images </papertitle>
                <br>
                    <em>Spring 2022</em>
                <br>
              Code:<a href="https://github.com/rohiitb/Two_view_stereo_3D_reconstruction"> Github</a>
                <br>
                <p>
                  In this project, we were given multiple images of a scene. We reconstructed the 3D pointcloud of the scene using 2 algorithms:<br>
                  <em>Two-View Stereo</em>: We generated the disparity map using distance metric kernels such as ssd, sad and zncc which gave the depth map of the scene.<br>
                  <em>Multiview Stereo</em>: We constructed a cost volume by stacking depth cost maps obtained by projecting reference view and warped neighboring view using homography.
                </p>
              </td>
            </tr> -->
          
          
          <!-- Autonomous Battle Bot -->
      <!--    <tr onmouseout="loss_stop()" onmouseover="loss_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/pic2.jpg' width="200" height="220">
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }

                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Autonomous Battle Bot</papertitle>
              <br>
              <em>Fall</em> 2021
              <br>
              Code: <a href="https://github.com/rohiitb/Autonomous_Battle_bot">Github</a>
              <p></p>
              <p>
                Designed and fabricated a 2-wheel differential drive robot with a gripper arm capable of grabbing cans and also detect light of desired frequencies.<br>
                Robot was also capable of navigating itself to a particular location using VIVE localization system.<br>
                ESP32 microcontroller was used for controlling and grabbing.<br>
                Wireless communication via HTML(Webpage) and UDP was used to send commands to the robot.
              </p>
            </td>
          </tr>

        </tbody></table>  -->
        
                <br><br><br>                <br><br><br>  


        
        
    <!--         Experience starts here-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td style="paddi0px;width:100%;vrtical-align:middle">
                <br>
                <br>
                <heading>Previous Work Experience and Education</heading>
              </td>
            </tr>
          </tbody>
        </table>
        <br>

  
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>University of Pune</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                August 2016 - October 2020
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Bachelor of Technology in Mechanical Engineering</papertitle>
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 9.32/10.0
              </td>              
            </tr>
          </tbody>
        </table>
    <!--    <b><u>Leadership Experience</u> : Team Taurus (Gokarting team, Pune University)</b>
        <ul>
          <li>Led a team of 20 members to design and manufacture a go-kart. Team comprised of different subsystems - Chassis, Engine and Transmission, Brake, Steering, Electrical. 
            A go-kart was manufactured from scratch using 125cc bike engine. All the components were designed optimally with considering factor of safety as well as weight.</li>
          <li>Achieved 3rd place in International Series of karting, 1st place in Kart Design Championship (Also won Best Design Award and Lightest kart) and 4th place in Indian karting championship. </li>
        </ul>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>  -->
<!--               <td style="paddi0px;width:50%;vrtical-align:middle"> -->
 <!--                           <td align = "center">

                <img src="./images/kdc.PNG" width="250" height="200">
              </td> -->
<!--               <td style="paddi0px;width:50%;vrtical-align:middle"> -->
<!--             <td align = "center">
                <img src="./images/ikc.jpeg" width="350" height="200">
              </td>              
            </tr>
            <tr>
              <td align = "center">
                <papertitle>KDC 2019</papertitle>
              </td>
              <td align = "center">
                <papertitle>IKC 2019</papertitle>
              </td>              
            </tr>
          </tbody>
        </table>
        
                        <br><br>  -->

  
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <br>
                <br>
                <papertitle>Atlas Copco GECIA</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                <br>
                <br>
                November 2020 - July 2022
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Design & Development Engineer</papertitle>
              </td> 
<!--               <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 3.75/4.0
              </td>               -->
            </tr>
          </tbody>
        </table>
        <ul>
          <li>Design of Engineered Oil-free compressors keeping standards , application , cost and safety into consideration. </li>
          <li>Extensive support to product company for customized 3D models, 2D, bill of materials , P&ID, Assembly instructions etc. </li>
          <li>Co-ordinated with cross-functional teams like PM, Electrical, production and quality to deliver timely output. </li>
          <li>Assisted Robotics Process Automation (RPA) team to automate the repetitive tasks in customized design process. </li>
        </ul>
                                <br><br>

  
  <!--
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Aespaes Labs Pvt Ltd</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                August 2020 - November 2020
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Artificial Intelligence Intern</papertitle>
              </td> -->
<!--               <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 3.75/4.0
              </td>               -->
<!--           </tr>
          </tbody>
        </table>
        <ul>
          <li>Deployed Augmented Reality project on Production Line of Bajaj Auto Ltd. by augmenting a blind spot at welding station on
            screen which helped workers to carry out welding operation with finesse.  </li>
          <li>Responsible for development and content mapping of VR Labs in Ed-tech. </li>
        </ul>
        
                        <br><br>  -->

  
<!--    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Automotive Research Association of India</papertitle> (Pune, India)
              </td>
              <td style="paddi0px;width:30%;vrtical-align:middle">
                July 2019 - December 2020
              </td>              
            </tr>
            <tr>
              <td style="paddi0px;width:70%;vrtical-align:middle">
                <papertitle>Project Intern (Structural Dynamics Lab)</papertitle>
              </td> -->
<!--               <td style="paddi0px;width:30%;vrtical-align:middle">
                GPA : 3.75/4.0
              </td>               -->
<!--         </tr>
          </tbody>
        </table>
        <ul>
          <li>Designed and drafted fixtures required for testing of automotive components including truck axles, railway chassis. </li>
          <li>Assisted in performing wide range of component testing such as durability, fatigue, vibration, static structural tests. </li>
          <li>Contributed in designing components for test equipment. </li>
        </ul>   -->

        
        <br><br><br>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                    Great thanks to Jon for his amazing <a href="https://jonbarron.info/">website template</a>!

              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  


</body>

</html>
